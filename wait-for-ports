#!/usr/bin/python3
import concurrent.futures
import errno
import json
import logging
import os
import re
import socket
import sys
import threading
import time
import traceback
import urllib
import urllib.parse
import urllib.request
import yaml

ENV_INIT_DEPENDENCIES = "INIT_DEPENDENCIES"

KEY_MODE = "mode"
KEY_URL = "url"
KEY_HTTP = "http"
KEY_HOST = "host"
KEY_PORT = "port"
KEY_PORTS = "ports" # Kept for backwards compatibility
KEY_DEPENDENCIES = "dependencies"
KEY_TEMPLATE = "template"
KEY_INITIAL_DELAY = "initialDelay"
KEY_DELAY = "delay"
KEY_TIMEOUT = "timeout"
KEY_ATTEMPTS = "attempts"

RESULT_UNKNOWN = 0
RESULT_SUCCESS = 1
RESULT_FAILURE = 2

MODE_ALL = "all"
MODE_ANY = "any"

MODES = { MODE_ALL : MODE_ALL, MODE_ANY : MODE_ANY }

DEFAULT_TEMPLATE = {
	KEY_MODE : MODE_ALL,
	KEY_URL : "",
	KEY_HTTP : "",
	KEY_HOST : "",
	KEY_INITIAL_DELAY : 0,
	KEY_DELAY : 5,
	KEY_TIMEOUT : 15,
	KEY_ATTEMPTS : 3
}

DEFAULT_DEPENDENCY_MODE = MODE_ALL
MIN_INITIAL_DELAY = 0
MIN_DELAY = 1
MIN_TIMEOUT = 1
MIN_ATTEMPTS = 1

SCHEME_PORTS = {
	"ftp" : 21,
	"ftps" : 990,
	"gopher" : 70,
	"http" : 80,
	"https" : 443,
	"ldap" : 389,
	"ldaps" : 636,
	"imap" : 143,
	"imaps" : 993,
	"pop" : 110,
	"pops" : 995,
	"smtp" : 25,
	"smtps" : 465,
	"ssh" : 22,
	"sftp" : 22,
	"telnet" : 23,
	"nfs" : 2049,
	"nntp" : 119,
}

RE_RFC_1123 = re.compile("^([a-z0-9][a-z0-9-]*)?[a-z0-9]([.]([a-z0-9][a-z0-9-]*)?[a-z0-9])*$")

def log_ok(msg):
	logging.info(f"✅ {msg}")

def log_warn(msg):
	logging.warning(f"⚠️ {msg}")

def log_err(msg):
	logging.error(f"❌ {msg}")

def fail(msg, code = 1):
	log_err(msg)
	os._exit(code)

def get_templated_value(m, k):
	try:
		v = m[k]
	except KeyError:
		try:
			v = DEFAULT_TEMPLATE[k]
		except KeyError:
			v = None
	return v

def resolve_port_from_scheme(scheme):
	if (scheme) and (scheme in SCHEME_PORTS):
		return int(SCHEME_PORTS[scheme])
	return None

def resolve_dynamic(value, label):
	# Only apply additional processing if it's a non-empty string
	if value:
		source = value
		if value.startswith("@env:"):
			# If it starts with "env:", it's an envvar value
			envvar = value[5:]
			logging.info(f"\t🔍 Resolving an alternate {label} from envvar [{envvar}]...")
			try:
				value = os.environ[envvar]
			except KeyError:
				fail(f"An alternate {label} from the environment variable [{envvar}] could not be resolved")
		elif value.startswith("@file:"):
			# If it starts with "file:", it's a file path
			file = value[6:]
			logging.info(f"\t💾 Resolving an alternate {label} from the file [{file}]...")
			try:
				with open(file, "r") as f:
					value = f.read().strip()
			except Exception as e:
				fail(f"An alternate {label} from the file [{file}] could not be resolved: {e}")
		else:
			# otherwise, assume it's a literal value and return it intact...
			# ... after expanding any environment variables within :)
			value = os.path.expandvars(value)
			logging.info(f"\t🔁 Using the alternate {label} [{value}]...")

		logging.info(f"\t\t🔦 The alternate {label} from [{source}] was resolved to [{value}]")
	return value

def resolve_url(url):
	return resolve_dynamic(url, "URL")

def resolve_host(hostname):
	return resolve_dynamic(hostname, "hostname")

def resolve_port(host, port):
	if port is None:
		return port

	# Always fold to a string, we'll unfold later as needed
	port = resolve_dynamic(str(port), f"port for host {host}")

	# Ok ... whatever we have is the final value, which can be either a port number or a port name
	try:
		return int(port)
	except ValueError:
		# Not a number ... is it a port name?
		try:
			return socket.getservbyname(port)
		except:
			fail(f"Port name [{port}] for host {host} could not be resolved from /etc/services")

class Lock:
	def __init__(self, rwl, myEnter, myExit):
		self.rwl = rwl
		self.enter = myEnter
		self.exit = myExit

	def __enter__(self):
		return self.enter()

	def __exit__(self, exc_type, exc_value, traceback):
		return self.exit()

	def lock(self):
		return self.enter()

	def unlock(self):
		return self.__exit__(None, None, None)

class ReadWriteLock:
	def __init__(self):
		self.__read_condition = threading.Condition()
		self.__reader_count = 0
		self.__read_lock = Lock(self, self.__acquire_read, self.__release_read)
		self.__write_lock = Lock(self, self.__acquire_write, self.__release_write)

	def readLock(self):
		return self.__read_lock

	def writeLock(self):
		return self.__write_lock

	def __acquire_read(self):
		self.__read_condition.acquire()
		try:
			self.__reader_count += 1
		finally:
			self.__read_condition.release()

	def __release_read(self):
		self.__read_condition.acquire()
		try:
			self.__reader_count -= 1
			if not self.__reader_count:
				self.__read_condition.notify_all()
		finally:
			self.__read_condition.release()

	def __acquire_write(self):
		self.__read_condition.acquire()
		while self.__reader_count > 0:
			self.__read_condition.wait()

	def __release_write(self):
		self.__read_condition.release()

class ThreadedCounter:
	def __init__(self, initialCount = 0):
		self.counter = int(initialCount)
		self.lock = ReadWriteLock()

	def add(self, count):
		count = int(count)
		with self.lock.writeLock():
			self.counter += count
			return self.counter

	def inc(self):
		return self.add(1)

	def sub(self, count):
		count = int(count)
		return self.add(-count)

	def dec(self):
		return self.add(-1)

	def get(self):
		with self.lock.readLock():
			return self.counter

	def set(self, value):
		value = int(value)
		with self.lock.writeLock():
			self.counter = value
			return self.counter

	def setIf(self, expected, value):
		expected = int(expected)
		value = int(value)

		with self.lock.writeLock():
			if self.counter == expected:
				self.counter = value
				return True
			return False

class ProbeException(Exception):
	def __init__(self, cause, must_report):
		super().__init__()
		self.cause = cause
		self.must_report = must_report

class DependencyProbe:
	def __init__(self, host, probe_url, initial_delay, delay, timeout, attempts, success, failure, get_final_result):
		self.host = host
		self.probe_url = probe_url
		self.initial_delay = initial_delay
		self.delay = delay
		self.timeout = timeout
		self.attempts = attempts
		self.success = success
		self.failure = failure
		self.get_final_result = get_final_result
		if probe_url.lower().startswith("tcp://"):
			self.probe = self.__probe_tcp
		else:
			self.probe = self.__probe_url

	def __is_silent_error(self, e):
		if e is None:
			return True
		t = type(e)
		if (t == OSError) and (e.errno in [ errno.EHOSTUNREACH, errno.EHOSTDOWN ]):
			return True
		if (t == socket.gaierror) and (e.errno in [ socket.EAI_AGAIN, socket.EAI_NODATA ]):
			return True
		return False

	def __set_result(self, result, exceptions):
		if result == RESULT_SUCCESS:
			self.success(self.probe_url)
		else:
			self.failure(self.probe_url, exceptions)

	def __probe_tcp(self):
		caught = None
		must_report = False
		url = urllib.parse.urlparse(self.probe_url)
		try:
			address = socket.gethostbyname(url.hostname)
			with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
				s.settimeout(self.timeout)
				s.connect((address, url.port))
				self.__set_result(RESULT_SUCCESS, None)
				return True
		except (socket.timeout, TimeoutError, ConnectionError) as e:
			caught = e
		except Exception as e:
			caught = e
			must_report = (not self.__is_silent_error(e))

		# Raise the exception
		raise ProbeException(caught, must_report)

	def __probe_url(self):
		caught = None
		must_report = True
		req = urllib.request.Request(self.probe_url)
		try:
			with urllib.request.urlopen(req) as rsp:
				return True
		except urllib.error.URLError as e:
			caught = e
			if type(e.reason) in [ BrokenPipeError, ConnectionAbortedError, ConnectionError, ConnectionRefusedError, ConnectionResetError, TimeoutError ]:
				must_report = False
		except urllib.error.HTTPError as e:
			caught = e
			must_report = (e.code not in [ 502, 503, 504 ])

		# Raise the exception
		raise ProbeException(caught, must_report)

	def check(self):
		exceptions = []
		for attempt in range(self.attempts):
			final_result = self.get_final_result()
			if final_result != RESULT_UNKNOWN:
				return (final_result == RESULT_SUCCESS)

			# Only on the first attempt ...
			if attempt == 1:
				# Apply any initial delay
				logging.info(f"\t⚡ Launching the prober thread for {self.probe_url}...")
				if (self.initial_delay > 0):
					logging.info(f"\t\t⏳ Applying the initial delay of {self.initial_delay}s...")
					time.sleep(self.initial_delay)

			caught = None
			report_caught = False
			try:
				logging.info(f"\t\t📡 Probing {self.probe_url} ({attempt + 1}/{self.attempts})...")
				if self.probe():
					return True
			except ProbeException as e:
				caught = e.cause
				report_caught = e.must_report
			finally:
				final_result = self.get_final_result()
				if final_result != RESULT_UNKNOWN:
					return (final_result == RESULT_SUCCESS)

				if caught:
					logging.error(f"\t\t❌ {self.probe_url} == {caught} (attempt # {attempt + 1} of {self.attempts})")
					exceptions.append(caught)
					if report_caught:
						log_err(traceback.format_exception(None, caught, caught.__traceback__))

			if (self.delay > 0) and ((attempt + 1) < self.attempts):
				logging.info(f"\t\t⏳ Applying a delay of {self.delay}s before the next attempt ({attempt + 2}/{self.attempts})...")
				time.sleep(self.delay)

		self.__set_result(RESULT_FAILURE, exceptions)
		return False

class Dependency:
	def __init__(self, host, obj):
		self.host = host

		# It must only have exactly one of a host-port combo, an http value, or a host-url
		has_url = (KEY_URL in obj)
		has_host_port = (KEY_HOST in obj) and ((KEY_PORT in obj) or (KEY_PORTS in obj))
		has_http = (KEY_HTTP in obj)

		sum_result = sum([has_url, has_host_port, has_http])
		if sum_result > 1:
			fail(f"The dependency declaration for {host} must contain exactly one of {KEY_URL}, {KEY_HTTP}, or {KEY_HOST} and {KEY_PORT}")
		elif sum_result == 0:
			# No entries, so use the key as the hostname
			has_host_port = True
			obj[KEY_HOST] = host
			# We'll catch any missing ports later

		probes = []

		if has_url or has_http:
			key = KEY_URL
			if has_http:
				key = KEY_HTTP

			url_source = obj.get(key)
			if not url_source:
				fail(f"The {key} probe for {host} contains an empty target")

			new_url = resolve_url(str(url_source).strip())
			if not new_url:
				fail(f"The {key} probe for {host} with a value of [{url_source}] was resolved to an empty target")

			new_url = urllib.parse.urlparse(new_url)

			if not new_url.scheme:
				fail(f"The {key} probe for {host} lacks a scheme: [{url_source}] -> [{new_url}]")

			# Capture the hostname from the URL
			if not new_url.hostname:
				fail(f"The {key} probe for {host} lacks a host specification: [{url_source}] -> [{new_url}]")

			self.host = new_url.hostname

			if has_http:
				if new_url.scheme.lower() not in [ "http", "https" ]:
					fail(f"The {key} probe for {host} has an invalid scheme specification of [{url_source}] -> [{new_url}] - must be either http or https")
				probes.append(new_url.geturl())
			else:
				port = new_url.port
				if port is None:
					# Deduce the port from the scheme...
					port = resolve_port_from_scheme(new_url.scheme)
					if not port:
						fail(f"The {key} probe for {host} has an unsupported URL scheme {new_url.scheme}: [{url_source}] -> [{new_url}]")
				probes.append(f"tcp://{new_url.hostname}:{port}")

		if has_host_port:
			if (KEY_PORT in obj) and (KEY_PORTS in obj):
				log_warn(f"Both {KEY_PORT} and {KEY_PORTS} sections are present in the configuration for {host}, the former will be ignored")

			try:
				port_source = obj[KEY_PORTS]
			except KeyError:
				try:
					port_source = obj[KEY_PORT]
				except KeyError:
					fail(f"The TCP probe for {host} has neither {KEY_PORT} nor {KEY_PORTS} specifications")

			host_source = obj.get(KEY_HOST)
			if not host_source:
				fail(f"The TCP probe for {host} contains an empty target")

			new_host = resolve_host(str(host_source).strip())
			if not new_host:
				fail(f"The TCP probe for {host} with a value of [{host_source}] was resolved to an empty target")

			self.host = new_host

			if type(port_source) != list:
				port_source = [ port_source ]

			for port in port_source:
				# If port is a string, it must be a service from /etc/services, or it's an error
				p = resolve_port(self.host, port)
				if (p < 1) or (p > 65535):
					fail(f"Port numbers must be between 1 and 65535: [{port}]")
				probes.append(f"tcp://{new_host}:{p}")

		# Check to see if the host is a valid, RFC-1123 hostname
		if not RE_RFC_1123.match(self.host.lower()):
			fail(f"Hostname [{self.host}] is not valid per RFC-1123")

		self.lock = threading.RLock()
		try:
			socket.gethostbyname(self.host)
		except Exception as e:
			# If this isn't a retryable lookup error, explode early
			if (type(e) != socket.gaierror) or (e.errno not in [ socket.EAI_AGAIN, socket.EAI_NODATA, socket.EAI_NONAME ]):
				fail(f"Hostname [{host}] could not be resolved - {e}")

		self.mode = str(get_templated_value(obj, KEY_MODE)).lower()
		if not (self.mode in MODES):
			fail(f"Mode for host [{self.host}] value [{obj['mode']}] is not valid - must be in {MODES.keys()} (case-insensitive)")

		initial_delay = int(get_templated_value(obj, KEY_INITIAL_DELAY))
		if initial_delay < 0:
			initial_delay = 0

		delay = int(get_templated_value(obj, KEY_DELAY))
		if delay < MIN_DELAY:
			delay = MIN_DELAY

		timeout = int(get_templated_value(obj, KEY_TIMEOUT))
		if timeout < MIN_TIMEOUT:
			timeout = MIN_TIMEOUT

		attempts = int(get_templated_value(obj, KEY_ATTEMPTS))
		if attempts < MIN_ATTEMPTS:
			attempts = MIN_ATTEMPTS

		self.active_probes = ThreadedCounter(0)
		self.final_result = ThreadedCounter(RESULT_UNKNOWN)
		self.probes = {}
		self.probe_futures = {}

		for probe_url in probes:
			self.probes[probe_url] = DependencyProbe(self.host, probe_url, initial_delay, delay, timeout, attempts, self.__probe_success, self.__probe_failure, self.__get_final_result)

	def __set_result_and_cancel_futures(self, result):
		if not self.final_result.setIf(RESULT_UNKNOWN, result):
			return

		if result == RESULT_SUCCESS:
			label = "SUCCESS"
		elif result == RESULT_FAILURE:
			label = "FAILURE"
		else:
			label = f"(unknown == {result})"

		logging.info(f"📢 Dependency [{self.host}] end result: {label}")
		for p, f in self.probe_futures.items():
			if f.done:
				continue
			logging.info(f"\t🚫 Canceling the future for the probe {p}")
			try:
				f.cancel()
			except:
				# We don't care...
				pass

		# Clear the remaining counter
		self.active_probes.set(0)

		# Signal upwards
		if result == 1:
			host_dependency_success(self.host)
		else:
			host_dependency_failure(self.host)

	def __get_final_result(self):
		return self.final_result.get()

	def __probe_success(self, probe_url):
		log_ok(f"Successfully probed {probe_url}")
		remaining = self.active_probes.dec()
		# If we're just waiting for the first success,
		# or all have succeeded, then we fire off the
		# global dependency success handler, and stop
		# all other port threads
		if (self.mode == MODE_ANY) or (remaining <= 0):
			self.__set_result_and_cancel_futures(RESULT_SUCCESS)

	def __probe_failure(self, probe_url, exceptions):
		exceptions = "\n\t".join([str(i) for i in exceptions])
		log_err(f"Probes to {probe_url} failed:\n\t{exceptions}")
		remaining = self.active_probes.dec()
		# If we're just waiting for the first failure,
		# or all have failed, then we fire off the
		# global dependency failure handler, and stop
		# all other probe threads
		if (self.mode == MODE_ALL) or (remaining <= 0):
			self.__set_result_and_cancel_futures(RESULT_FAILURE)

	def get_probe_count(self):
		return len(self.probes)

	def start(self, executor):
		# Start the pollers for all the probes
		self.active_probes.set(len(self.probes))
		logging.info(f"\t👀 Starting the probes for [{self.host}] (ports required for success: {self.mode})")
		for p, P in self.probes.items():
			logging.info(f"\t\t👁️ Starting the probe for {p}")
			future = executor.submit(P.check)
			self.probe_futures[p] = future
		return self.probe_futures.values()

def host_dependency_success(name):
	# Subtract one from the global dependency counter
	remaining = total_dependencies.dec()
	if (host_dependency_mode == MODE_ALL) and (remaining > 0):
		# We must wait for all remaining dependencies to succeed, so we do nothing
		log_warn(f"There are still {remaining} unresolved dependencies...")
		return False

	# We can exit now if this is the last dependency to succeed,
	# or if we were only waiting for the first dependency to succeed
	if host_dependency_mode == MODE_ALL:
		log_ok("All required dependencies have succeeded. Exiting with a success status.")
	else:
		log_ok("One dependency has succeeded, and only one was required to succeed. Exiting with a success status")
	os._exit(0)

def host_dependency_failure(name):
	# Subtract one from the global dependency counter
	remaining = total_dependencies.dec()
	if (host_dependency_mode == MODE_ANY) and (remaining > 0):
		# We must wait for all remaining dependencies to fail, so we do nothing
		log_warn(f"There are still {remaining} unresolved dependencies...")
		return False

	# We can exit now if this is the last dependency to fail,
	# or if we were only waiting for the first dependency to fail
	if host_dependency_mode == MODE_ALL:
		fail("A dependency has failed, but all were required to succeed. Exiting with an error status")
	fail("All required dependencies have failed where at least one was required to succeed. Exiting with an error status")

if len(sys.argv) != 2:
	# If no parameter is given, use an environment variable
	if ENV_INIT_DEPENDENCIES in os.environ:
		source_file = os.environ[ENV_INIT_DEPENDENCIES]
		# Check if this points to a file ...
		source_file_is_file = (os.path.exists(source_file) and os.path.isfile(source_file))
	else:
		print(f"usage: {sys.argv[0]} [dependency-file]")
		print("")
		print(f"\tIf the file is not given, its path will be read from the environment variable {ENV_INIT_DEPENDENCIES},")
		print(f"\twhich may also contain the configuration data directly, for convenience in containerized")
		print(f"\tenvironments and the like.")
		sys.exit(1)
else:
	# If the parameter is given, use it
	source_file = sys.argv[1]
	if source_file == "-":
		source_file = sys.stdin
		source_file_is_file = False
	else:
		source_file_is_file = True

# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logging.basicConfig(level=logging.DEBUG, format = '%(asctime)s - %(threadName)-10s - %(levelname)s - %(message)s')

# First try to load as a YAML file ... if that fails, try with JSON ...

show_data = True
try:
	if source_file_is_file:
		logging.info(f"💾 Loading the configuration from the file [{source_file}]...")
		with open(source_file, "r") as f:
			data = yaml.safe_load(f)
	else:
		if type(source_file) == str:
			logging.info(f"🧾 Parsing the configuration from the string: [\n{source_file}\n]...")
			show_data = False
		else:
			logging.info("⚙️ Parsing the configuration from stdin...")
		data = yaml.safe_load(source_file)
	if data is None:
		raise Exception("Data is not in YAML format")
except Exception as e:
	# Yaml parse failed ... try as JSON
	log_warn(f"File [{source_file}] was not in YAML format, trying JSON")
	try:
		with open(source_file, "r") as f:
			data = json.load(f)
	except Exception as e:
		logging.error(e)
		sys.exit(1)

if show_data:
	log_ok(f"Loaded configuration: [{json.dumps(data, indent=4)}]")

host_dependency_mode = str(data.get("mode", DEFAULT_DEPENDENCY_MODE)).lower()
if not (host_dependency_mode in MODES):
	log_err(f"The host dependency mode value [{host_dependency_mode}] is not valid - must be in {MODES.keys()} (case-insensitive)")
	sys.exit(1)

try:
	hosts = data[KEY_DEPENDENCIES]
except KeyError:
	log_ok(f"No dependencies found in the configuration file at [{source_file}]")
	sys.exit(0)

logging.info(f"🚨 Dependency mode: {host_dependency_mode} required")

#
# Make sure the template values are in range
#
dependency_template = data.get(KEY_TEMPLATE, {})
for k in DEFAULT_TEMPLATE:
	if k in dependency_template:
		v = dependency_template[k]
		t = type(DEFAULT_TEMPLATE[k])
		if type(v) != t:
			try:
				v = t(v)
			except:
				log_err(f"The dependency template value [{k}] of [{v}] can't be cast to type {t}")
				sys.exit(1)
		DEFAULT_TEMPLATE[k] = v

# Sanitize the values
if not (DEFAULT_TEMPLATE[KEY_MODE] in MODES):
	log_err(f"The dependency template mode [{DEFAULT_TEMPLATE[KEY_MODE]}] is not valid - must be in {MODES.keys()} (case-insensitive)")
	sys.exit(1)
if DEFAULT_TEMPLATE[KEY_INITIAL_DELAY] < MIN_INITIAL_DELAY:
	DEFAULT_TEMPLATE[KEY_INITIAL_DELAY] = MIN_INITIAL_DELAY
if DEFAULT_TEMPLATE[KEY_DELAY] < MIN_DELAY:
	DEFAULT_TEMPLATE[KEY_DELAY] = MIN_DELAY
if DEFAULT_TEMPLATE[KEY_TIMEOUT] < MIN_TIMEOUT:
	DEFAULT_TEMPLATE[KEY_TIMEOUT] = MIN_TIMEOUT
if DEFAULT_TEMPLATE[KEY_ATTEMPTS] < MIN_ATTEMPTS:
	DEFAULT_TEMPLATE[KEY_ATTEMPTS] = MIN_ATTEMPTS

logging.info(f"👀 Dependency template:\n{json.dumps(DEFAULT_TEMPLATE, indent=4)}")

total_threads = 0
dependencies = {}
for host, obj in hosts.items():
	logging.info(f"➡️ Found a dependency on host '{host}' = {json.dumps(obj, indent=4)}")
	dependencies[host] = Dependency(host, obj)
	threads = dependencies[host].get_probe_count()
	total_threads += threads

total_dependencies = ThreadedCounter(len(hosts))
try:
	logging.info(f"🧵 Starting the {total_threads} threads (hosts required for success: {host_dependency_mode})...")
	with concurrent.futures.ThreadPoolExecutor(max_workers=(total_threads + 1), thread_name_prefix="Probe") as executor:
		futures = []
		for h, d in dependencies.items():
			futures.extend(d.start(executor))
		logging.info(f"💤 Waiting for the work to conclude ({len(futures)} futures)")
		for f in futures:
			try:
				f.result()
			except Exception as e:
				log_error(traceback.format_exc())
				# We don't care...
				pass
		sys.exit(0)
except KeyboardInterrupt:
	fail("INTERRUPTED!")
