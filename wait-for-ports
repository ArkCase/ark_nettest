#!/usr/bin/python
import concurrent.futures
import errno
import json
import logging
import os
import re
import socket
import sys
import threading
import time
import traceback
import urllib
import urllib.parse
import yaml

ENV_INIT_DEPENDENCIES = "INIT_DEPENDENCIES"

KEY_MODE = "mode"
KEY_URL = "url"
KEY_HOST = "host"
KEY_PORT = "port"
KEY_PORTS = "ports" # Kept for backwards compatibility
KEY_DEPENDENCIES = "dependencies"
KEY_TEMPLATE = "template"
KEY_INITIAL_DELAY = "initialDelay"
KEY_DELAY = "delay"
KEY_TIMEOUT = "timeout"
KEY_ATTEMPTS = "attempts"

MODE_ALL = "all"
MODE_ANY = "any"

MODES = { MODE_ALL : MODE_ALL, MODE_ANY : MODE_ANY }

DEFAULT_TEMPLATE = {
	KEY_MODE : MODE_ALL,
	KEY_URL : "",
	KEY_HOST : "",
	KEY_INITIAL_DELAY : 0,
	KEY_DELAY : 5,
	KEY_TIMEOUT : 15,
	KEY_ATTEMPTS : 3
}

DEFAULT_DEPENDENCY_MODE = MODE_ALL
MIN_INITIAL_DELAY = 0
MIN_DELAY = 1
MIN_TIMEOUT = 1
MIN_ATTEMPTS = 1

SCHEME_PORTS = {
	"ftp" : 21,
	"ftps" : 990,
	"gopher" : 70,
	"http" : 80,
	"https" : 443,
	"ldap" : 389,
	"ldaps" : 636,
	"imap" : 143,
	"imaps" : 993,
	"pop" : 110,
	"pops" : 995,
	"smtp" : 25,
	"smtps" : 465,
	"ssh" : 22,
	"sftp" : 22,
	"telnet" : 23,
	"nfs" : 2049,
	"nntp" : 119,
}

RE_RFC_1123 = re.compile("^([a-z0-9][a-z0-9-]*)?[a-z0-9]([.]([a-z0-9][a-z0-9-]*)?[a-z0-9])*$")

def log_ok(msg):
	logging.info(f"‚úÖ {msg}")

def log_warn(msg):
	logging.warning(f"‚ö†Ô∏è {msg}")

def log_err(msg):
	logging.error(f"‚ùå {msg}")

def fail(msg, code = 1):
	log_err(msg)
	os._exit(code)

def get_templated_value(m, k):
	try:
		v = m[k]
	except KeyError:
		try:
			v = DEFAULT_TEMPLATE[k]
		except KeyError:
			v = None
	return v

def resolve_port_from_scheme(scheme):
	if (scheme) and (scheme in SCHEME_PORTS):
		return int(SCHEME_PORTS[scheme])
	return None

def resolve_dynamic(value, label):
	# Only apply additional processing if it's a non-empty string
	if value:
		source = value
		if value.startswith("@env:"):
			# If it starts with "env:", it's an envvar value
			envvar = value[5:]
			logging.info(f"\tüîç Resolving an alternate {label} from envvar [{envvar}]...")
			try:
				value = os.environ[envvar]
			except KeyError:
				fail(f"An alternate {label} from the environment variable [{envvar}] could not be resolved")
		elif value.startswith("@file:"):
			# If it starts with "file:", it's a file path
			file = value[6:]
			logging.info(f"\tüíæ Resolving an alternate {label} from the file [{file}]...")
			try:
				with open(file, "r") as f:
					value = f.read().strip()
			except Exception as e:
				fail(f"An alternate {label} from the file [{file}] could not be resolved: {e}")
		else:
			# otherwise, assume it's a literal value and return it intact...
			logging.info(f"\tüîÅ Using the alternate {label} [{value}]...")

		logging.info(f"\t\tüî¶ The alternate {label} from [{source}] was resolved to [{value}]")
	return value

def resolve_url(url):
	return resolve_dynamic(url, "URL")

def resolve_host(hostname):
	return resolve_dynamic(hostname, "hostname")

def resolve_port(host, port):
	if port is None:
		return port

	# Always fold to a string, we'll unfold later as needed
	port = resolve_dynamic(str(port), f"port for host {host}")

	# Ok ... whatever we have is the final value, which can be either a port number or a port name
	try:
		return int(port)
	except ValueError:
		# Not a number ... is it a port name?
		try:
			return socket.getservbyname(port)
		except:
			fail(f"Port name [{port}] for host {host} could not be resolved from /etc/services")

class Lock:
	def __init__(self, rwl, myEnter, myExit):
		self.rwl = rwl
		self.enter = myEnter
		self.exit = myExit

	def __enter__(self):
		return self.enter()

	def __exit__(self, exc_type, exc_value, traceback):
		return self.exit()

	def lock(self):
		return self.enter()

	def unlock(self):
		return self.__exit__(None, None, None)

class ReadWriteLock:
	def __init__(self):
		self.__read_condition = threading.Condition()
		self.__reader_count = 0
		self.__read_lock = Lock(self, self.__acquire_read, self.__release_read)
		self.__write_lock = Lock(self, self.__acquire_write, self.__release_write)

	def readLock(self):
		return self.__read_lock

	def writeLock(self):
		return self.__write_lock

	def __acquire_read(self):
		self.__read_condition.acquire()
		try:
			self.__reader_count += 1
		finally:
			self.__read_condition.release()

	def __release_read(self):
		self.__read_condition.acquire()
		try:
			self.__reader_count -= 1
			if not self.__reader_count:
				self.__read_condition.notify_all()
		finally:
			self.__read_condition.release()

	def __acquire_write(self):
		self.__read_condition.acquire()
		while self.__reader_count > 0:
			self.__read_condition.wait()

	def __release_write(self):
		self.__read_condition.release()

class ThreadedCounter:
	def __init__(self, initialCount = 0):
		self.counter = int(initialCount)
		self.lock = ReadWriteLock()

	def add(self, count):
		count = int(count)
		with self.lock.writeLock():
			self.counter += count
			return self.counter

	def inc(self):
		return self.add(1)

	def sub(self, count):
		count = int(count)
		return self.add(-count)

	def dec(self):
		return self.add(-1)

	def get(self):
		with self.lock.readLock():
			return self.counter

	def set(self, value):
		value = int(value)
		with self.lock.writeLock():
			self.counter = value
			return self.counter

	def setIf(self, expected, value):
		expected = int(expected)
		value = int(value)

		with self.lock.writeLock():
			if self.counter == expected:
				self.counter = value
				return True
			return False

class DependencyPort:
	def __init__(self, host, port, initial_delay, delay, timeout, attempts, success, failure, final_result):
		self.host = host
		self.port = port
		self.initial_delay = initial_delay
		self.delay = delay
		self.timeout = timeout
		self.attempts = attempts
		self.success = success
		self.failure = failure
		self.final_result = final_result

	def __is_silent_error(self, e):
		if e is None:
			return True
		t = type(e)
		if (t == OSError) and (e.errno in [ errno.EHOSTUNREACH, errno.EHOSTDOWN ]):
			return True
		if (t == socket.gaierror) and (e.errno in [ socket.EAI_AGAIN, socket.EAI_NODATA ]):
			return True
		return False

	def check(self):
		# Apply any initial delay
		logging.info(f"\t‚ö° Launching the prober thread for {self.host}:{self.port}...")
		if (self.initial_delay > 0):
			logging.info(f"\t\t‚è≥ Applying the initial delay of {self.initial_delay}s...")
			time.sleep(self.initial_delay)

		exceptions = []
		for attempt in range(self.attempts):
			caught = None
			report_caught = False
			try:
				logging.info(f"\t\tüì° Probing {self.host}:{self.port} ({attempt + 1}/{self.attempts})...")
				address = socket.gethostbyname(self.host)
				with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
					s.settimeout(self.timeout)
					s.connect((address, self.port))
					self.success(self.port)
					return True
			except (socket.timeout, TimeoutError, ConnectionError) as e:
				caught = e
			except Exception as e:
				caught = e
				if not self.__is_silent_error(e):
					report_caught = True
			finally:
				final_result = self.final_result.get()
				if final_result != 0:
					return (final_result == 1)

				if caught:
					logging.error(f"\t\t‚ùå tcptest({self.host}, {self.port}, {self.timeout}) == {caught} (attempt # {attempt + 1} of {self.attempts})")
					exceptions.append(caught)
					if report_caught:
						log_err(traceback.format_exception(None, caught, caught.__traceback__))

			if (self.delay > 0) and ((attempt + 1) < self.attempts):
				logging.info(f"\t\t‚è≥ Applying a delay of {self.delay}s before the next attempt ({attempt + 2}/{self.attempts})...")
				time.sleep(self.delay)

		self.failure(self.port, exceptions)
		return False

class Dependency:
	def __init__(self, host, obj):
		self.host = host

		# It must only have either a host-port combo, or a url, not both
		port_source = None
		if (KEY_URL in obj) and ((KEY_HOST in obj) or (KEY_PORT in obj) or (KEY_PORTS in obj)):
			fail(f"The host declaration for {host} contains both a {KEY_URL} section and a {KEY_HOST}/{KEY_PORT} section - this is not allowed")

		if KEY_URL in obj:
			url_source = str(get_templated_value(obj, KEY_URL))
			if url_source:
				new_url = resolve_url(url_source)
				if new_url:
					new_url = urllib.parse.urlparse(new_url)

					if not new_url.scheme:
						fail(f"The URL for {host} lacks a scheme: {url_source}")

					# Capture the hostname from the URL
					if not new_url.hostname:
						fail(f"The URL for {host} lacks a host specification: [{url_source}]")
					self.host = new_url.hostname

					if new_url.port is None:
						# Deduce the port from the scheme...
						port_source = resolve_port_from_scheme(new_url.scheme)
						if not port_source:
							fail(f"Unsupported URL scheme {new_url.scheme} from the URL for {host}: {url_source}")
					else:
						port_source = [ new_url.port ]
		elif KEY_HOST in obj:
			host_source = str(get_templated_value(obj, KEY_HOST))
			if host_source:
				new_host = resolve_host(host_source)
				if new_host:
					# If we got a value, strip it ...
					new_host = new_host.strip();

					# If the stripped value is empty, this is an error
					if not new_host:
						raise Exception(f"The alternate hostname from [{host_source}] resolved to an empty value")

					# Use the alternate hostname
					self.host = new_host

		# Check to see if the host is a valid, RFC-1123 hostname
		if not RE_RFC_1123.match(self.host.lower()):
			fail(f"Hostname [{self.host}] is not valid per RFC-1123")

		self.lock = threading.RLock()
		try:
			socket.gethostbyname(self.host)
		except Exception as e:
			# If this isn't a retryable lookup error, explode early
			if (type(e) != socket.gaierror) or (e.errno not in [ socket.EAI_AGAIN, socket.EAI_NODATA, socket.EAI_NONAME ]):
				fail(f"Hostname [{host}] could not be resolved - {e}")

		self.mode = str(get_templated_value(obj, KEY_MODE)).lower()
		if not (self.mode in MODES):
			fail(f"Mode for host [{self.host}] value [{obj['mode']}] is not valid - must be in {MODES.keys()} (case-insensitive)")

		initial_delay = int(get_templated_value(obj, KEY_INITIAL_DELAY))
		if initial_delay < 0:
			initial_delay = 0

		delay = int(get_templated_value(obj, KEY_DELAY))
		if delay < MIN_DELAY:
			delay = MIN_DELAY

		timeout = int(get_templated_value(obj, KEY_TIMEOUT))
		if timeout < MIN_TIMEOUT:
			timeout = MIN_TIMEOUT

		attempts = int(get_templated_value(obj, KEY_ATTEMPTS))
		if attempts < MIN_ATTEMPTS:
			attempts = MIN_ATTEMPTS

		self.active_ports = ThreadedCounter(0)
		self.final_result = ThreadedCounter(0)
		self.ports = {}
		self.port_futures = {}

		if not port_source:
			if (KEY_PORT in obj) and (KEY_PORTS in obj):
				log_warn(f"Both {KEY_PORT} and {KEY_PORTS} sections are present in the configuration for {host}, the latter will be ignored")
			try:
				port_source = obj[KEY_PORT]
			except KeyError:
				try:
					port_source = obj[KEY_PORTS]
				except KeyError:
					fail(f"The dependency declaration for host {host} has no port source (no URL, and no {KEY_PORT} section)")

		if type(port_source) != list:
			port_source = [ port_source ]

		for port in port_source:
			# If port is a string, it must be a service from /etc/services, or it's an error
			p = resolve_port(self.host, port)
			if (p < 1) or (p > 65535):
				fail(f"Port [{port}] must be between 1 and 65535")

			self.ports[p] = DependencyPort(self.host, p, initial_delay, delay, timeout, attempts, self.__port_success, self.__port_failure, self.final_result)

	def __set_result_and_cancel_futures(self, result):
		if self.final_result.setIf(0, result):
			if result == 1:
				label = "SUCCESS"
			else:
				label = "FAILURE"
			logging.info(f"üì¢ Dependency [{self.host}] end result: {label}")
			for p, f in self.port_futures.items():
				if f.done:
					continue
				logging.info(f"\tüö´ Canceling the future for [{self.host}:{p}]")
				try:
					f.cancel()
				except:
					# We don't care...
					pass

			# Clear the remaining counter
			self.active_ports.set(0)

			# Signal upwards
			if result == 1:
				host_dependency_success(self.host)
			else:
				host_dependency_failure(self.host)

	def __port_success(self, port):
		log_ok(f"Successfully probed [{self.host}:{port}]")
		remaining = self.active_ports.dec()
		# If we're just waiting for the first success,
		# or all have succeeded, then we fire off the
		# global dependency success handler, and stop
		# all other port threads
		if (self.mode == MODE_ANY) or (remaining <= 0):
			self.__set_result_and_cancel_futures(1)

	def __port_failure(self, port, exceptions):
		exceptions = "\n\t".join([str(i) for i in exceptions])
		log_err(f"Probes to [{self.host}:{port}] failed:\n\t{exceptions}")
		remaining = self.active_ports.dec()
		# If we're just waiting for the first failure,
		# or all have failed, then we fire off the
		# global dependency failure handler, and stop
		# all other port threads
		if (self.mode == MODE_ALL) or (remaining <= 0):
			self.__set_result_and_cancel_futures(2)

	def get_port_count(self):
		return len(self.ports)

	def start(self, executor):
		# Start the pollers for all the internal ports
		self.active_ports.set(len(self.ports))
		logging.info(f"\tüëÄ Starting the probes for [{self.host}] (ports required for success: {self.mode})")
		for p, P in self.ports.items():
			logging.info(f"\t\tüëÅÔ∏è Starting the probe for {self.host}:{p}")
			future = executor.submit(P.check)
			self.port_futures[p] = future
		return self.port_futures.values()

def host_dependency_success(name):
	# Subtract one from the global dependency counter
	remaining = total_dependencies.dec()
	if (host_dependency_mode == MODE_ALL) and (remaining > 0):
		# We must wait for all remaining dependencies to succeed, so we do nothing
		log_warn(f"‚ö†Ô∏è There are still {remaining} unresolved dependencies...")
		return False

	# We can exit now if this is the last dependency to succeed,
	# or if we were only waiting for the first dependency to succeed
	if host_dependency_mode == MODE_ALL:
		log_ok("All required dependencies have succeeded. Exiting with a success status.")
	else:
		log_ok("One dependency has succeeded, and only one was required to succeed. Exiting with a success status")
	os._exit(0)

def host_dependency_failure(name):
	# Subtract one from the global dependency counter
	remaining = total_dependencies.dec()
	if (host_dependency_mode == MODE_ANY) and (remaining > 0):
		# We must wait for all remaining dependencies to fail, so we do nothing
		log_warn(f"There are still {remaining} unresolved dependencies...")
		return False

	# We can exit now if this is the last dependency to fail,
	# or if we were only waiting for the first dependency to fail
	if host_dependency_mode == MODE_ALL:
		fail("A dependency has failed, but all were required to succeed. Exiting with an error status")
	fail("All required dependencies have failed where at least one was required to succeed. Exiting with an error status")

if len(sys.argv) != 2:
	# If no parameter is given, use an environment variable
	if ENV_INIT_DEPENDENCIES in os.environ:
		source_file = os.environ[ENV_INIT_DEPENDENCIES]
		# Check if this points to a file ...
		source_file_is_file = (os.path.exists(source_file) and os.path.isfile(source_file))
	else:
		print(f"usage: {sys.argv[0]} [dependency-file]")
		print("")
		print(f"\tIf the file is not given, its path will be read from the environment variable {ENV_INIT_DEPENDENCIES},")
		print(f"\twhich may also contain the configuration data directly, for convenience in containerized")
		print(f"\tenvironments and the like.")
		sys.exit(1)
else:
	# If the parameter is given, use it
	source_file = sys.argv[1]
	if source_file == "-":
		source_file = sys.stdin
		source_file_is_file = False
	else:
		source_file_is_file = True

# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logging.basicConfig(level=logging.DEBUG, format = '%(asctime)s - %(threadName)-10s - %(levelname)s - %(message)s')

# First try to load as a YAML file ... if that fails, try with JSON ...

show_data = True
try:
	if source_file_is_file:
		logging.info(f"üíæ Loading the configuration from the file [{source_file}]...")
		with open(source_file, "r") as f:
			data = yaml.safe_load(f)
	else:
		if type(source_file) == str:
			logging.info(f"üßæ Parsing the configuration from the string: [\n{source_file}\n]...")
			show_data = False
		else:
			logging.info("‚öôÔ∏è Parsing the configuration from stdin...")
		data = yaml.safe_load(source_file)
	if data is None:
		raise Exception("Data is not in YAML format")
except Exception as e:
	# Yaml parse failed ... try as JSON
	log_warn(f"File [{source_file}] was not in YAML format, trying JSON")
	try:
		with open(source_file, "r") as f:
			data = json.load(f)
	except Exception as e:
		logging.error(e)
		sys.exit(1)

if show_data:
	log_ok(f"Loaded configuration: [{json.dumps(data, indent=4)}]")

host_dependency_mode = str(data.get("mode", DEFAULT_DEPENDENCY_MODE)).lower()
if not (host_dependency_mode in MODES):
	log_err(f"The host dependency mode value [{host_dependency_mode}] is not valid - must be in {MODES.keys()} (case-insensitive)")
	sys.exit(1)

try:
	hosts = data[KEY_DEPENDENCIES]
except KeyError:
	log_ok(f"No dependencies found in the configuration file at [{source_file}]")
	sys.exit(0)

logging.info(f"üö® Dependency mode: {host_dependency_mode} required")

#
# Make sure the template values are in range
#
dependency_template = data.get(KEY_TEMPLATE, {})
for k in DEFAULT_TEMPLATE:
	if k in dependency_template:
		v = dependency_template[k]
		t = type(DEFAULT_TEMPLATE[k])
		if type(v) != t:
			try:
				v = t(v)
			except:
				log_err(f"The dependency template value [{k}] of [{v}] can't be cast to type {t}")
				sys.exit(1)
		DEFAULT_TEMPLATE[k] = v

# Sanitize the values
if not (DEFAULT_TEMPLATE[KEY_MODE] in MODES):
	log_err(f"The dependency template mode [{DEFAULT_TEMPLATE[KEY_MODE]}] is not valid - must be in {MODES.keys()} (case-insensitive)")
	sys.exit(1)
if DEFAULT_TEMPLATE[KEY_INITIAL_DELAY] < MIN_INITIAL_DELAY:
	DEFAULT_TEMPLATE[KEY_INITIAL_DELAY] = MIN_INITIAL_DELAY
if DEFAULT_TEMPLATE[KEY_DELAY] < MIN_DELAY:
	DEFAULT_TEMPLATE[KEY_DELAY] = MIN_DELAY
if DEFAULT_TEMPLATE[KEY_TIMEOUT] < MIN_TIMEOUT:
	DEFAULT_TEMPLATE[KEY_TIMEOUT] = MIN_TIMEOUT
if DEFAULT_TEMPLATE[KEY_ATTEMPTS] < MIN_ATTEMPTS:
	DEFAULT_TEMPLATE[KEY_ATTEMPTS] = MIN_ATTEMPTS

logging.info(f"üëÄ Dependency template:\n{json.dumps(DEFAULT_TEMPLATE, indent=4)}")

total_threads = 0
dependencies = {}
for host, obj in hosts.items():
	logging.info(f"‚û°Ô∏è Found a dependency on host [{host}]...")
	dependencies[host] = Dependency(host, obj)
	threads = dependencies[host].get_port_count()
	total_threads += threads
	logging.info(f"üëÄ '{host}' = {json.dumps(obj, indent=4)}")

total_dependencies = ThreadedCounter(len(hosts))
try:
	logging.info(f"üßµ Starting the {total_threads} threads (hosts required for success: {host_dependency_mode})...")
	with concurrent.futures.ThreadPoolExecutor(max_workers=(total_threads + 1), thread_name_prefix="Probe") as executor:
		futures = []
		for h, d in dependencies.items():
			futures.extend(d.start(executor))
		logging.info(f"üí§ Waiting for the work to conclude ({len(futures)} futures)")
		for f in futures:
			try:
				f.result()
			except Exception as e:
				log_error(traceback.format_exc())
				# We don't care...
				pass
		sys.exit(0)
except KeyboardInterrupt:
	fail("INTERRUPTED!")
